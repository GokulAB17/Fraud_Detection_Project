# -*- coding: utf-8 -*-
"""final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ra0VkjZXvj9t-3rWG2G0DfMQEUKHeRzU

## Problem Statement: Predict whether given Hospital Insuarance Claim is Graud or genuine.

* Author: Gokul Â© 2021


****
****

# Step 1: Importing Libraries..
"""

import numpy as np 
import pandas as pd

import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.utils import resample
from sklearn.preprocessing import LabelBinarizer, LabelEncoder
from sklearn.model_selection import train_test_split, cross_val_score

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix

from sklearn.model_selection import StratifiedKFold 
from collections import Counter

from joblib import dump, load

import warnings
warnings.filterwarnings('ignore')


pd.set_option('display.max_columns', 2000)
pd.set_option('display.max_rows', 500)

"""# Step 2: Dataset loading and Preprocessing.."""

dataset = pd.read_csv('dataset.csv')

dataset.head(2)

dataset.columns

# removing spaces in dataset column names..

dataset.columns = dataset.columns.to_series().apply(lambda x: x.replace(' ', '_')).to_list()
dataset.columns = dataset.columns.to_series().apply(lambda x: x.replace('/', '_')).to_list()
dataset.columns.values

dataset.rename(columns={'Home_or_self_care,': 'Home_or_self_care'}, inplace=True)

data= pd.read_csv('dataset.csv')
data_sample_view = data.head(2)

# for deployment part...sample dataframe view..
dump(data_sample_view, 'data_sample_view.joblib')

dataset.shape

dataset.drop_duplicates(inplace=True)

dataset.dropna(inplace=True)

dataset.shape

dataset.info()

dataset.select_dtypes(include=['object']).head(2)

"""* It shows days spend hspt column as obejct type. So checking unique values & dealing with it."""

#### trying to convert string formatted data to integer / find out which value is not getting converted to integer datatype

for i in dataset.Days_spend_hsptl.unique():
    try:
        int(i)
    except ValueError:
        print(i)

"""So we have '120 +' entry in Days_spend_hsptl column. that is days spend hospital is more than 120..

So we can replace it by integer 120 & Convert this column to integer dataype
"""

# replacing value

dataset.replace({'Days_spend_hsptl': '120 +'}, 120, inplace=True)

# converting to intger datatype column..

dataset.Days_spend_hsptl = dataset.Days_spend_hsptl.astype('int')

dataset.select_dtypes(exclude='object').head(2)

dataset.Hospital_Id = dataset.Hospital_Id.astype('int')
dataset.Mortality_risk = dataset.Mortality_risk.astype('int')

sample_test_data = dataset.copy()

"""##### Dropping non-importanat columns...source: EDA-Discussion-part-II"""

dataset.drop(['Hospital_Id', 'apr_drg_description', 'Abortion', 'Weight_baby'], axis=1, inplace=True)

dataset.head(2)

"""### encoding...

#### Making it for deployment ppoint of view..
"""

dataset.select_dtypes(include=['object']).head(2)

from sklearn.preprocessing import LabelBinarizer, LabelEncoder
label = LabelEncoder()
label_binizer =LabelBinarizer()

label_area = label.fit(dataset.Area_Service)

label_Hospital_County = label.fit(dataset.Hospital_County)

label_Age = label.fit(dataset.Age)

label_Cultural_group = label.fit(dataset.Cultural_group)

label_ethnicity= label.fit(dataset.ethnicity)

label_Admission_type = label.fit(dataset.Admission_type)

label_Home_or_self_care = label.fit(dataset.Home_or_self_care)

one_hot_Gender = label_binizer.fit(dataset.Gender)
one_hot_Surg_Description = label_binizer.fit(dataset.Surg_Description)
one_hot_Emergency_dept_yes_No = label_binizer.fit(dataset.Emergency_dept_yes_No)

label_encoder_list = [label_area, label_Hospital_County,
                label_Age, label_Cultural_group,
                label_ethnicity, label_Admission_type,
                label_Home_or_self_care]

one_hot_coder_list = [one_hot_Gender, one_hot_Surg_Description, one_hot_Emergency_dept_yes_No]

"""#### pickling encoding object & columns for deployment point of view..."""

from joblib import dump

dump(label_encoder_list, 'label_encoder_list.joblib')

dump(one_hot_coder_list, 'one_hot_coder_list.joblib')

label_to_column = ['Area_Service', 'Hospital_County',
                  'Age', 'Cultural_group', 'ethnicity',
                  'Admission_type', 'Home_or_self_care']

one_hot_column = ['Gender', 'Surg_Description', 'Emergency_dept_yes_No']

dump(label_to_column, 'label_to_column.joblib')

dump(one_hot_column, 'one_hot_column.joblib')

# applyibng label encoding on columns..also this below cells can be used in deployment as well

dataset.head()

j = 0
for i in label_to_column:
    dataset[i] = label_encoder_list[j].fit_transform(dataset[i])
    j =+1

# applyibng one hot encoding on columns..also this below cells can be used in deployment as well

k = 0
for i in one_hot_column:
    dataset[i] = one_hot_coder_list[k].fit_transform(dataset[i])
    k =+1

dataset.head()

"""### Data Imbalance..."""

sns.countplot(dataset.Result)
plt.show()

"""# Step 3: Model By different strategy...

#### Performing on sample datasets...
"""

# taking 5% sample data from whole dataset

sample_data = dataset.sample(frac=0.02)

# checking for result column unique values counts..

sample_data.Result.value_counts()

sns.countplot(sample_data.Result)
plt.show()

"""## 3.1 Upsampling before splitting the data into train & test
****
"""

# seperating '0', & '1' label 

sample_minority = sample_data.loc[sample_data['Result']==0]
sample_majority = sample_data.loc[sample_data['Result']==1]

# doing upsampling of minority classes... taking 100 to 80% ratio

# sample_majority.shape[0]*0.80

from sklearn.utils import resample
sample_data_minority_upsampled = resample(sample_minority , replace=True, n_samples=12000, random_state=42)

# combining upsampled data to majority class data...

sample_data_upsampled = pd.concat([sample_majority, sample_data_minority_upsampled ], ignore_index=True)

# seperating indepedent & depedent variabales..

x = sample_data_upsampled.drop(['Result'],axis=1).values
y = sample_data_upsampled.Result.values

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify = y, random_state=42)

# finding best ccp_alph tree prunning parameter. So that it will avoid overfit issue

def find_alpha(x_train, x_test, y_train, y_test):
    
    import matplotlib.pyplot as plt
    from sklearn.ensemble import RandomForestClassifier
    
    
    ccp_alphas = np.arange(0.000, 0.040, 0.002)
    clfs = []
    for ccp_alpha in ccp_alphas:
        clf = RandomForestClassifier(n_estimators=15, random_state=42, ccp_alpha=ccp_alpha)
        clf.fit(x_train, y_train)
        clfs.append(clf)

    train_scores = [clf.score(x_train, y_train) for clf in clfs]
    test_scores = [clf.score(x_test, y_test) for clf in clfs]

    fig, ax = plt.subplots(figsize=(15,6))
    ax.set_xlabel("alpha")
    ax.set_ylabel("accuracy")
    ax.set_title("Accuracy vs alpha for training and testing sets")
    ax.plot(ccp_alphas, train_scores, marker='o', label="train",drawstyle="steps-post")
    ax.plot(ccp_alphas, test_scores, marker='o', label="test",drawstyle="steps-post")
    ax.set_xticks(np.arange(0.000,0.040, 0.002))
    ax.set_yticks(np.arange(0.70,1.01, 0.1))
    ax.legend()
    plt.grid(True)
    plt.rcParams['xtick.labelsize']=12
    plt.rcParams['ytick.labelsize']=12
    plt.show()

find_alpha(x_train, x_test, y_train, y_test)

"""* ccp_alph parameter should be zero for this case.

### Building Model with n_estimators=100
"""

from sklearn.ensemble import RandomForestClassifier
sample_RF_upsampled = RandomForestClassifier(n_estimators=100, random_state=42)

clf_sample = sample_RF_upsampled.fit(x_train, y_train)

y_pred_train = clf_sample.predict(x_train)
y_pred = clf_sample.predict(x_test)

print(classification_report(y_train, y_pred_train ))

print(classification_report(y_test, y_pred ))

cross_val_score(clf_sample, x, y)

"""### Building Model with n_estimators=15"""

from sklearn.ensemble import RandomForestClassifier
sample_RF15_upsampled = RandomForestClassifier(n_estimators=15, random_state=42)

clf_15_sample = sample_RF_upsampled.fit(x_train, y_train)

y_pred_train = clf_15_sample.predict(x_train)
y_pred = clf_15_sample.predict(x_test)

print(classification_report(y_train, y_pred_train ))

print(classification_report(y_test, y_pred ))

cross_val_score(clf_15_sample, x, y)

y_pred_whole = clf_15_sample.predict(dataset.drop(['Result'],axis=1))

print(classification_report(dataset.Result.values, y_pred_whole))

"""## 3.2 Upsampling after train_test_split...

### 3.1 Upsampling using sklearn resample
"""

x = sample_data.drop(['Result'],axis=1).values
y = sample_data.Result.values

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify = y, random_state=42)

from collections import Counter
Counter(y_train)

x_train_df = pd.DataFrame(x_train, columns=sample_data.drop(['Result'],axis=1).columns)
y_train_df = pd.DataFrame(y_train, columns=['Result'])

df_train = pd.concat([x_train_df, y_train_df],axis=1)

df_train_majority = df_train.loc[df_train['Result']==1]
df_train_minority = df_train.loc[df_train['Result']==0]

df_train_majority.shape

df_train_minority.shape

# checking 80% row counts w.r.t majority class
12487*0.80

# doing upsampling of minority classes... taking 100 to 80% ratio

# sample_majority.shape[0]*0.80

from sklearn.utils import resample
df_train_minority_upsampled = resample(df_train_minority , replace=True, n_samples=9990, random_state=42)

after_split_upsampled = pd.concat([df_train_majority, df_train_minority_upsampled])

# splitting into x_train, y_train only..note: we have alerady splitted test sets using k fold...

x_train_upsampled = after_split_upsampled.drop(['Result'],axis=1).values
y_train_upsampled = after_split_upsampled.Result.values

from sklearn.ensemble import RandomForestClassifier
sample_RF15_after_split_upsampled = RandomForestClassifier(n_estimators=15, random_state=42)

sample_RF15_after_split_upsampled = sample_RF15_after_split_upsampled.fit(x_train_upsampled, y_train_upsampled)

y_pred_train = sample_RF15_after_split_upsampled.predict(x_train_upsampled)
y_pred = sample_RF15_after_split_upsampled.predict(x_test)

Counter(y_test)

print(classification_report(y_train_upsampled, y_pred_train ))

print(classification_report(y_test, y_pred ))

"""### Conclusion:

* It is clear that, upsampling tech. is best suited for imbalanced dataset..when we upsample minority class before train_test_split

# Step 4: Model Building On whole dataset...
"""

data_minority = dataset.loc[dataset['Result']==0]
data_majority = dataset.loc[dataset['Result']==1]

from sklearn.utils import resample
data_minority_upsampled = resample(data_minority, replace=True, n_samples=624290, random_state=42)
data_upsampled = pd.concat([data_majority, data_minority_upsampled ], ignore_index=True)

X = data_upsampled.drop(['Result'],axis=1).values
Y = data_upsampled.Result.values

x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=30)

from sklearn.ensemble import RandomForestClassifier
model_rf_upsampled = RandomForestClassifier(n_estimators=15, random_state=42)

model_rf_upsampled.fit(x_train, y_train)

y_pred_train = model_rf_upsampled.predict(x_train)
y_pred_test = model_rf_upsampled.predict(x_test)

# classification report...for train set
print(classification_report(y_train, y_pred_train))

# classification report...for test set
print(classification_report(y_test, y_pred_test))

y_pred_whole = model_rf_upsampled.predict(dataset.drop(['Result'],axis=1))

print(classification_report(dataset.Result.values, y_pred_whole))

"""#### Saving model..."""

from joblib import dump, load
dump(model_rf_upsampled, 'model_rf_upsampled.joblib')

from sklearn.metrics import f1_score

skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1) 
lst_accu_stratified = [] 

x = dataset.drop(['Result'],axis=1).values
y = dataset.Result.values
   
for train_index, test_index in skf.split(x, y): 
    x_train_fold, x_test_fold = x[train_index], x[test_index] 
    y_train_fold, y_test_fold = y[train_index], y[test_index] 
    model_rf_upsampled.fit(x_train_fold, y_train_fold)
    lst_accu_stratified.append(f1_score(y_test_fold, model_rf_upsampled.predict(x_test_fold)))

# Print the output. 
print('List of possible F1 score:', lst_accu_stratified) 
print('\nMaximum F1 score That can be obtained from this model is:', 
      (np.round(max(lst_accu_stratified)*100, 2)))
print('\nMinimum F1 score:', 
      (np.round(min(lst_accu_stratified)*100,2))) 
print('\nOverall F1 score:', 
     (np.round(np.mean(lst_accu_stratified)*100,2)))
print('\nStandard Deviation is:', np.round(np.std(lst_accu_stratified)))

"""#### predicting on different samples from dataset

### Building model for small sample for deployment purpose
"""

# taking sample data from dataset..

sample = dataset.sample(9000)

sample.head(2)

sample.shape

index= sample.index.to_list()

# checking memory size of sample data..

sample.info()

"""* Now it is showing 6 MB size which will be ok for deployment part of view.

* Note: This model will may not be good fit on whole dataset. F1 score, Accuracy may drop in large proportion
"""

# Checking for imbalance state

sample.Result.value_counts()

# # seperating majority & minority classes

sample_1 = sample.loc[sample['Result']==1]
sample_0 = sample.loc[sample['Result']==0]

# and will do downsampling of class '1'

from sklearn.utils import resample
sample_0 = resample(sample_0, replace=True, n_samples=5500, random_state=42)

sample_upsampled = pd.concat([sample_0, sample_1], ignore_index=True)

sample_upsampled.shape

sample_upsampled.head()

# Checking for imbalance state

sample_upsampled.Result.value_counts(normalize=True)

sample_upsampled.info()

X = sample_upsampled.drop(['Result'],axis=1).values
Y = sample_upsampled.Result.values

x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=30)

from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier(n_estimators=15, random_state=42)

model = model.fit(x_train, y_train)

y_pred_train = model.predict(x_train)
y_pred_test = model.predict(x_test)

# classification report...for train set
print(classification_report(y_train, y_pred_train))

# classification report...for train set
print(classification_report(y_test, y_pred_test))

y_pred_whole = model.predict(sample.drop(['Result'],axis=1))

print(classification_report(sample.Result.values, y_pred_whole))

sns.heatmap(confusion_matrix(sample.Result.values, y_pred_whole), annot=True, fmt='.8g')
plt.show()

# from sklearn.metrics import f1_score

# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1) 
# lst_accu_stratified = [] 

# x = dataset.drop(['Result'],axis=1).values
# y = dataset.Result.values
   
# for train_index, test_index in skf.split(x, y): 
#     x_train_fold, x_test_fold = x[train_index], x[test_index] 
#     y_train_fold, y_test_fold = y[train_index], y[test_index] 
#     model.fit(x_train_fold, y_train_fold)
#     lst_accu_stratified.append(f1_score(y_test_fold, model.predict(x_test_fold)))

# # Print the output. 
# print('List of possible F1 score:', lst_accu_stratified) 
# print('\nMaximum F1 score That can be obtained from this model is:', 
#       (np.round(max(lst_accu_stratified)*100, 2)))
# print('\nMinimum F1 score:', 
#       (np.round(min(lst_accu_stratified)*100,2))) 
# print('\nOverall F1 score:', 
#      (np.round(np.mean(lst_accu_stratified)*100,2)))
# print('\nStandard Deviation is:', np.round(np.std(lst_accu_stratified)))

"""### Saving Model"""

from joblib import dump, load
dump(model, 'model.joblib')

"""##### Saving sample data to deployment trial"""

index = sample.index.to_list()

sample_test_data = sample_test_data.loc[index]

sample_test_data.to_csv('sample_test_data.csv', index=False)

